{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f16c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "206bc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]= \"\"\n",
    "LANGCHAIN_TRACING_V2=\"true\"\n",
    "LANGCHAIN_API_KEY= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae2461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page(url):\n",
    "    text=requests.get(url)\n",
    "    soup=BeautifulSoup(text.text,\"html.parser\")\n",
    "    return soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73dcd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detector(query):\n",
    "    lang_url=\"https://ddragon.leagueoflegends.com/cdn/languages.json\"\n",
    "    text_langs=extract_page(lang_url).split('\"')\n",
    "\n",
    "    list_langs=[]\n",
    "    for lang in range(1,len(text_langs),2):\n",
    "        list_langs.append(text_langs[lang])\n",
    "\n",
    "    determinate_lang=f\"\"\"You are an expert to determinate what language a text is in.\n",
    "    You are an expert because you always check the whole text to determinate what overall language is used.\n",
    "    You always provide a single language among the following list: {list_langs}\n",
    "    You always provide only the language, nothing more.\n",
    "    Here is a text:\n",
    "    {query}\"\"\"\n",
    "\n",
    "    lang=llm.invoke(determinate_lang).content\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c070ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def champion_detector(query):\n",
    "    champ_url=\"https://ddragon.leagueoflegends.com/cdn/15.23.1/data/en_US/champion.json\"\n",
    "    champ_page=requests.get(champ_url).json()\n",
    "    champs=[champ for champ in champ_page[\"data\"]]\n",
    "\n",
    "    determinate_champ=f\"\"\"You are an expert to determinate what League Of Legends champions are related to a text.\n",
    "    You are an expert because you always check the list of League Of Legends champions and then you compare it to the text.\n",
    "    You provide as many champions as mentionned in the text and present in this list: {champs}\n",
    "    You always provide the list of related champions as followed: [\\\"champion_name1\\\",\\\"champion_name2\\\"] with as many names as related.\n",
    "    Here is a text:\n",
    "    {query}\"\"\"\n",
    "\n",
    "    champions=llm.invoke(determinate_champ).content.split('\"')\n",
    "    champions_list=[]\n",
    "\n",
    "    for champ in range(1,len(champions),2):\n",
    "        champions_list.append(champions[champ])\n",
    "\n",
    "    return champions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500c7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES_CHAMP=[\n",
    "    \"allytips\",\n",
    "    \"enemytips\",\n",
    "    \"tags\",\n",
    "    \"partype\",\n",
    "    \"info\",\n",
    "    \"stats\",\n",
    "    \"spells\",\n",
    "    \"passive\",\n",
    "    \"recommended\"\n",
    "]\n",
    "\n",
    "def champ_infos(lang,champion):\n",
    "    champ_url=f\"https://ddragon.leagueoflegends.com/cdn/15.23.1/data/{lang}/champion/{champion}.json\"\n",
    "    champ_page=requests.get(champ_url).json()[\"data\"][champion]\n",
    "    return [champ_page[infos] for infos in champ_page if infos in ATTRIBUTES_CHAMP and champ_page[infos]!=[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf48531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici quelques conseils pour jouer Orianna contre Akali :\n",
      "\n",
      "1. Utilisez votre compétence \"Ordre : Protection\" pour vous protéger des attaques d'Akali. Le bouclier et les dégâts magiques infligés peuvent vous aider à contrer ses attaques.\n",
      "\n",
      "2. Utilisez \"Ordre : Dissonance\" pour ralentir Akali et l'empêcher de s'approcher de vous trop facilement. Cela peut vous aider à maintenir une distance sécurisée.\n",
      "\n",
      "3. Gardez un œil sur la position de la sphère d'Orianna et utilisez-la stratégiquement pour contrôler l'espace et empêcher Akali de s'approcher trop près.\n",
      "\n",
      "4. Profitez de la portée de vos compétences pour harceler Akali à distance et éviter les échanges de coups directs.\n",
      "\n",
      "En suivant ces conseils et en adaptant votre style de jeu, vous devriez être en mesure de mieux affronter Akali en tant qu'Orianna midlane. Bonne chance !\n"
     ]
    }
   ],
   "source": [
    "def rag_answer(query):\n",
    "    lang=language_detector(query)\n",
    "    champions_list=champion_detector(query)\n",
    "    infos_champions=[champ_infos(lang,champ) for champ in champions_list]\n",
    "\n",
    "    prompt=f\"\"\"You are a very skillful player of League Of Legends.\\\n",
    "    You give really useful and uncommon tips to play specific champions.\\\n",
    "    You always use data of champions to give the tips.\\\n",
    "    You also analyse statistiques to give uncommon and very useful tips.\\\n",
    "    You always use all the knowedges to give good tips when you see a query.\\\n",
    "    You always answer is the language associated to {lang}\\\n",
    "    Here are champions: {champions_list}\\\n",
    "    Here are data of champions: {infos_champions}\\\n",
    "    Here is a query: {query}\"\"\"\n",
    "\n",
    "    answer=llm.invoke(prompt).content\n",
    "    return answer\n",
    "\n",
    "print(rag_answer(\"J'adore jouer Orianna midlane mais je fais que perdre contre Akali.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7e1d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building retriever...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_23404\\1174825200.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  emb=OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Building retriever...\")\n",
    "\n",
    "    emb=OpenAIEmbeddings()\n",
    "    llm=ChatOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            print('-' * 50)\n",
    "            question=input(\"Posez une question :\\n> \")\n",
    "            print()\n",
    "            print(rag_answer(question))\n",
    "            print(\"\\n\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExiting...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
